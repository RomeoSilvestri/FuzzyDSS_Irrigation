{
 "cells": [
  {
   "cell_type": "code",
   "id": "f82c57c4-28ff-44d0-b6e2-0c91d907fb97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T12:39:56.664405Z",
     "start_time": "2024-07-22T12:39:28.085868Z"
    }
   },
   "source": [
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, pairwise_distances_argmin_min\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from joblib import Parallel, delayed\n",
    "from tabulate import tabulate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6b02af40-05cd-4e08-af3d-3d95c42f40f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T12:39:56.756340Z",
     "start_time": "2024-07-22T12:39:56.664405Z"
    }
   },
   "source": [
    "def calculate_distortion(X_normalized, cluster_centers):\n",
    "    cluster_centers_reduced = cluster_centers.reshape((cluster_centers.shape[0], -1))\n",
    "    return sum(np.min(pairwise_distances_argmin_min(cluster_centers_reduced, X_normalized.reshape((X_normalized.shape[0], -1)), metric=\"euclidean\"), axis=1))**2\n",
    "\n",
    "\n",
    "def calculate_aic(y_true, y_pred, num_features):\n",
    "    resid = y_true - y_pred\n",
    "    sse = np.sum(resid ** 2)\n",
    "    aic = len(y_true) * np.log(sse / len(y_true)) + 2 * num_features\n",
    "    return aic\n",
    "\n",
    "\n",
    "def calculate_bic(y_true, y_pred, num_features):\n",
    "    resid = y_true - y_pred\n",
    "    sse = np.sum(resid ** 2)\n",
    "    n = len(y_true)\n",
    "    bic = n * np.log(sse / n) + num_features * np.log(n)\n",
    "    return bic\n",
    "\n",
    "\n",
    "def forward_step(X_train, y_train, selected_features, remaining_features, criterion_func):\n",
    "    best_criterion = np.inf\n",
    "    best_feature = None\n",
    "    temp_model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "    temp_predictions = temp_model.predict(sm.add_constant(X_train[selected_features]))\n",
    "    for feature in remaining_features:\n",
    "        temp_features = selected_features + [feature]\n",
    "        temp_model = sm.OLS(y_train, sm.add_constant(X_train[temp_features])).fit()\n",
    "        temp_criterion = criterion_func(y_train, temp_model.predict(sm.add_constant(X_train[temp_features])), len(temp_model.params))\n",
    "        \n",
    "        if temp_criterion < best_criterion:\n",
    "            best_criterion = temp_criterion\n",
    "            best_feature = feature\n",
    "    \n",
    "    return best_criterion, best_feature\n",
    "\n",
    "def backward_step(X_train, y_train, selected_features, criterion_func):\n",
    "    best_criterion = np.inf\n",
    "    best_feature = None\n",
    "    temp_model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "    temp_predictions = temp_model.predict(sm.add_constant(X_train[selected_features]))\n",
    "    for feature in selected_features:\n",
    "        temp_features = selected_features.copy()\n",
    "        temp_features.remove(feature)\n",
    "        temp_model = sm.OLS(y_train, sm.add_constant(X_train[temp_features])).fit()\n",
    "        temp_criterion = criterion_func(y_train, temp_model.predict(sm.add_constant(X_train[temp_features])), len(temp_model.params))\n",
    "        \n",
    "        if temp_criterion < best_criterion:\n",
    "            best_criterion = temp_criterion\n",
    "            best_feature = feature\n",
    "    \n",
    "    return best_criterion, best_feature\n",
    "\n",
    "def stepwise_bidirectional_selection(X_train, y_train, method='aic'):\n",
    "    features = list(X_train.columns)\n",
    "    selected_features = []\n",
    "    best_criterion = np.inf\n",
    "    \n",
    "    while len(features) > 0:\n",
    "        if method == 'aic':\n",
    "            forward_criterion, forward_feature = forward_step(X_train, y_train, selected_features, features, calculate_aic)\n",
    "            backward_criterion, backward_feature = backward_step(X_train, y_train, selected_features, calculate_aic)\n",
    "        elif method == 'bic':\n",
    "            forward_criterion, forward_feature = forward_step(X_train, y_train, selected_features, features, calculate_bic)\n",
    "            backward_criterion, backward_feature = backward_step(X_train, y_train, selected_features, calculate_bic)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid criterion_func. Use 'aic' or 'bic'.\")\n",
    "        \n",
    "        if forward_criterion < backward_criterion and forward_criterion < best_criterion:\n",
    "            selected_features.append(forward_feature)\n",
    "            best_criterion = forward_criterion\n",
    "        elif backward_criterion < forward_criterion and backward_criterion < best_criterion:\n",
    "            selected_features.remove(backward_feature)\n",
    "            best_criterion = backward_criterion\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    mean_y_true = np.mean(y_true)\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - mean_y_true) ** 2)\n",
    "    \n",
    "    r_squared_value = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    return r_squared_value\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    non_zero_indices = np.where(y_true != 0)[0]\n",
    "    y_true_no_zeros = np.array(y_true)[non_zero_indices]\n",
    "    y_pred_no_zeros = np.array(y_pred)[non_zero_indices]\n",
    "\n",
    "    absolute_percentage_errors = np.abs((y_true_no_zeros - y_pred_no_zeros) / y_true_no_zeros)\n",
    "    mape_value = np.mean(absolute_percentage_errors) * 100\n",
    "    return mape_value\n",
    "\n",
    "def mape_std(y_true, y_pred):\n",
    "    mape_value = mape(y_true, y_pred)\n",
    "    \n",
    "    non_zero_indices = np.where(y_true != 0)[0]\n",
    "    y_true_no_zeros = np.array(y_true)[non_zero_indices]\n",
    "    y_pred_no_zeros = np.array(y_pred)[non_zero_indices]\n",
    "\n",
    "    absolute_percentage_errors = np.abs((y_true_no_zeros - y_pred_no_zeros) / y_true_no_zeros)\n",
    "    \n",
    "    mape_sd_value = np.sqrt(np.mean((absolute_percentage_errors - mape_value / 100) ** 2))\n",
    "    \n",
    "    return mape_sd_value\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def rmse_std(y_true, y_pred):\n",
    "    return np.std(np.sqrt((y_true - y_pred) ** 2))\n",
    "\n",
    "\n",
    "def optimize_ncomp_pls(X, y, n_comp_range, ylabel, objective):\n",
    "    errors = []\n",
    "    xticks = np.arange(1, n_comp_range + 1)\n",
    "\n",
    "    for n_comp in xticks:\n",
    "        pls = PLSRegression(n_components=n_comp)\n",
    "        y_cv = cross_val_predict(pls, X, y, cv=10)\n",
    "        error = rmse(y, y_cv)\n",
    "        errors.append(error)\n",
    "\n",
    "    if objective == 'min':\n",
    "        return xticks[np.argmin(errors)]\n",
    "    else:\n",
    "        return xticks[np.argmax(errors)]\n",
    "\n",
    "\n",
    "def show_figure(sensor_target_id,\n",
    "                y_baseline,\n",
    "                y_train,\n",
    "                y_pred,\n",
    "                y_test,\n",
    "                y_predictions,\n",
    "                irrigation_train,\n",
    "                rain_train,\n",
    "                irrigation_test,\n",
    "                rain_test):\n",
    "\n",
    "    all_data_train = np.concatenate([y_train, y_pred])\n",
    "    all_data_test = np.concatenate([y_baseline, y_test, y_predictions])\n",
    "    max_value_train = np.max(all_data_train)\n",
    "    max_value_test = np.max(all_data_test)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    irrigation_train_scaled = scaler.fit_transform(np.array(irrigation_train).reshape(-1, 1)).flatten()*max_value_train\n",
    "    rain_train_scaled = scaler.fit_transform(np.array(rain_train).reshape(-1, 1)).flatten()*max_value_train\n",
    "    irrigation_test_scaled = scaler.fit_transform(np.array(irrigation_test).reshape(-1, 1)).flatten()*max_value_test\n",
    "    rain_test_scaled = scaler.fit_transform(np.array(rain_test).reshape(-1, 1)).flatten()*max_value_test\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1, subplot_titles=('<b>Training</b>', '<b>Testing</b>'), vertical_spacing=0.1)\n",
    "    fig.update_annotations(yshift=10)\n",
    "\n",
    "    date_range = [datetime.datetime(2023, 5, 1) + datetime.timedelta(days=i) for i in range(len(y_test))]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[i for i in range(len(rain_train_scaled))], y=np.round(rain_train_scaled, 2),\n",
    "            mode='lines',\n",
    "            line=dict(color='cyan'),\n",
    "            marker_size=3,\n",
    "            marker_symbol='circle',\n",
    "            name='Rain',\n",
    "            showlegend=True,\n",
    "            customdata=np.round(rain_train, 2),\n",
    "            hovertemplate='Rain: %{customdata}<extra></extra>',\n",
    "            marker_color='white',\n",
    "            marker=dict(line=dict(color='cyan', width=2))\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[i for i in range(len(irrigation_train_scaled))], y=np.round(irrigation_train_scaled, 2),\n",
    "            mode='lines',\n",
    "            line=dict(color='lime'),\n",
    "            marker_size=3,\n",
    "            marker_symbol='circle',\n",
    "            name='Irrigation',\n",
    "            showlegend=True,\n",
    "            customdata=np.round(irrigation_train, 2),\n",
    "            hovertemplate='Irrigation: %{customdata}<extra></extra>',\n",
    "            marker_color='white',\n",
    "            marker=dict(line=dict(color='lime', width=2))\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[i for i in range(len(y_pred))], y=np.round(y_pred, 2),\n",
    "            mode='lines',\n",
    "            line=dict(color='green'),\n",
    "            marker_size=3,\n",
    "            marker_symbol='circle',\n",
    "            name='Predictions',\n",
    "            showlegend=True,\n",
    "            marker_color='white',\n",
    "            marker=dict(line=dict(color='green', width=2))\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[i for i in range(len(y_train))], y=np.round(y_train, 2),\n",
    "            mode='lines',\n",
    "            line=dict(color='blue'),\n",
    "            marker_size=3,\n",
    "            marker_symbol='circle',\n",
    "            name='Ground-truth',\n",
    "            showlegend=True,\n",
    "            marker_color='white',\n",
    "            marker=dict(line=dict(color='blue', width=2))\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[i for i in range(len(y_pred))], y=np.round(y_pred - y_train, 2),\n",
    "            mode='markers',\n",
    "            line=dict(color='red'),\n",
    "            marker_size=3,\n",
    "            marker_symbol='circle',\n",
    "            name='Residuals',\n",
    "            showlegend=True,\n",
    "            marker_color='white',\n",
    "            marker=dict(line=dict(color='red', width=2))\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=date_range, y=np.round(rain_test_scaled, 2),\n",
    "            mode='lines',\n",
    "            line=dict(color='cyan'),\n",
    "            marker_size=3,\n",
    "            marker_symbol='circle',\n",
    "            name='Rain',\n",
    "            showlegend=False,\n",
    "            customdata=np.round(rain_test, 2),\n",
    "            hovertemplate='Rain: %{customdata}<extra></extra>',\n",
    "            marker_color='white',\n",
    "            marker=dict(line=dict(color='cyan', width=2))\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=date_range, y=np.round(irrigation_test_scaled, 2),\n",
    "            mode='lines',\n",
    "            line=dict(color='lime'),\n",
    "            marker_size=3,\n",
    "            marker_symbol='circle',\n",
    "            name='Irrigation',\n",
    "            showlegend=False,\n",
    "            customdata=np.round(irrigation_test, 2),\n",
    "            hovertemplate='Irrigation: %{customdata}<extra></extra>',\n",
    "            marker_color='white',\n",
    "            marker=dict(line=dict(color='lime', width=2))\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=date_range, y=np.round(y_predictions, 2),\n",
    "            mode='lines',\n",
    "            line=dict(color='green'),\n",
    "            marker_size=3,\n",
    "            marker_symbol='circle',\n",
    "            name='Predictions',\n",
    "            showlegend=False,\n",
    "            marker_color='white',\n",
    "            marker=dict(line=dict(color='green', width=2))\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=date_range, y=np.round(y_test, 2),\n",
    "            mode='lines',\n",
    "            line=dict(color='blue'),\n",
    "            marker_size=3,\n",
    "            marker_symbol='circle',\n",
    "            name='Ground-truth',\n",
    "            showlegend=False,\n",
    "            marker_color='white',\n",
    "            marker=dict(line=dict(color='blue', width=2))\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=date_range, y=np.round(y_predictions - y_test, 2),\n",
    "            mode='markers',\n",
    "            line=dict(color='red'),\n",
    "            marker_size=3,\n",
    "            marker_symbol='circle',\n",
    "            name='Residuals',\n",
    "            showlegend=False,\n",
    "            marker_color='white',\n",
    "            marker=dict(line=dict(color='red', width=2))\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=date_range, y=np.round(y_baseline - y_test, 2),\n",
    "            mode='markers',\n",
    "            line=dict(color='orange'),\n",
    "            marker_size=3,\n",
    "            marker_symbol='circle',\n",
    "            name='Residuals baseline',\n",
    "            showlegend=True,\n",
    "            marker_color='white',\n",
    "            marker=dict(line=dict(color='orange', width=2))\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text='<b>Sensor ' + str(sensor_target_id) + '</b>',\n",
    "            font=dict(\n",
    "                size=18 \n",
    "            )\n",
    "        ),\n",
    "        autosize=False,\n",
    "        width=2000,\n",
    "        height=1000,\n",
    "        margin=dict(\n",
    "            l=50,\n",
    "            r=50,\n",
    "            b=100,\n",
    "            t=100,\n",
    "            pad=4\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "    fig.write_image(os.path.join('plots', 'sensor_' + str(sensor_target_id) + '_plot.png'))  "
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3008c82c-67b7-4a57-b2c5-e10453f6d6ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T12:39:58.379644Z",
     "start_time": "2024-07-22T12:39:56.758780Z"
    }
   },
   "source": [
    "df = pd.read_csv('data_sensors_rovere.csv')\n",
    "df = df.rename(columns={'group': 'group_id'})\n",
    "\n",
    "df_rovere = df[['reading_id', 'timestamp', 'sensor_id', 'value', 'description', 'group_id']]\n",
    "\n",
    "df_rovere['reading_id'] = df_rovere['reading_id'].astype(str)\n",
    "df_rovere['timestamp'] = pd.to_datetime(df_rovere['timestamp']).dt.floor('D').dt.date\n",
    "df_rovere['sensor_id'] = df_rovere['sensor_id'].astype(str)\n",
    "df_rovere['value'] = df_rovere['value'].astype(float)\n",
    "df_rovere['description'] = df_rovere['description'].astype(str)\n",
    "df_rovere['group_id'] = df_rovere['group_id'].astype(str)\n",
    "\n",
    "tens_30 = ['72', '76', '73', '74', '61', '63', '67', '65']\n",
    "tens_60 = ['71', '69', '75', '70', '62', '64', '68', '66']\n",
    "tens_all = tens_30 + tens_60\n",
    "    \n",
    "condition_30 = df_rovere['sensor_id'].isin(tens_30)\n",
    "condition_60 = df_rovere['sensor_id'].isin(tens_60)\n",
    "condition_irrigation = df_rovere['description'] == 'irrigation'\n",
    "    \n",
    "df_rovere.loc[condition_30, 'description'] = 'Tensiometer 30'\n",
    "df_rovere.loc[condition_60, 'description'] = 'Tensiometer 60'\n",
    "df_rovere.loc[condition_irrigation, 'description'] = 'Irrigation'\n",
    "\n",
    "condition_not_in_list = ~df_rovere['sensor_id'].isin(tens_all)\n",
    "df_to_duplicate = df_rovere[condition_not_in_list]\n",
    "df_to_duplicate['group_id_1'] = df_to_duplicate['group_id'] + '_1'\n",
    "    \n",
    "df_rovere = pd.concat([df_rovere, df_to_duplicate], ignore_index=True)\n",
    "df_rovere.sort_values(by=['group_id', 'timestamp'], inplace=True)\n",
    "df_rovere.reset_index(drop=True, inplace=True)\n",
    "\n",
    "condition_group_id_1 = df_rovere['group_id_1'].notnull()\n",
    "df_rovere.loc[condition_group_id_1, 'group_id'] = df_rovere.loc[condition_group_id_1, 'group_id_1']\n",
    "df_rovere.drop(columns=['group_id_1'], inplace=True)\n",
    "\n",
    "condition_update_group_id = df_rovere['sensor_id'].isin(tens_60)\n",
    "df_rovere.loc[condition_update_group_id, 'group_id'] = df_rovere.loc[condition_update_group_id, 'group_id'] + '_1'\n",
    "\n",
    "\n",
    "df_group = df_rovere.groupby(['timestamp', 'description', 'sensor_id', 'group_id']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "df_group.columns = ['timestamp', 'description', 'sensor_id', 'group_id', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "df_pivot = df_group.pivot(index=['timestamp', 'group_id'], columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "df_pivot.columns.name = None\n",
    "df_pivot.columns = ['date', 'group_id', 'min_hum', 'min_temp', 'min_solar', 'min_wind', 'min_irr', 'min_rain', 'min_tens30', 'min_tens60',\n",
    "                    'max_hum', 'max_temp', 'max_solar', 'max_wind', 'max_irr', 'max_rain', 'max_tens30', 'max_tens60',\n",
    "                    'avg_hum', 'avg_temp', 'avg_solar', 'avg_wind', 'avg_irr', 'avg_rain', 'avg_tens30', 'avg_tens60',\n",
    "                    'med_hum', 'med_temp', 'med_solar', 'med_wind', 'med_irr', 'med_rain', 'med_tens30', 'med_tens60',\n",
    "                    'sum_hum', 'sum_temp', 'sum_solar', 'sum_wind', 'sum_irr', 'sum_rain', 'sum_tens30', 'sum_tens60']\n",
    "\n",
    "df_pivot['min_tens'] = df_pivot['min_tens30'].combine_first(df_pivot['min_tens60'])\n",
    "df_pivot.drop(columns=['min_tens30', 'min_tens60'], inplace=True)\n",
    "\n",
    "\n",
    "df_pivot['max_tens'] = df_pivot['max_tens30'].combine_first(df_pivot['max_tens60'])\n",
    "df_pivot.drop(columns=['max_tens30', 'max_tens60'], inplace=True)\n",
    "\n",
    "\n",
    "df_pivot['avg_tens'] = df_pivot['avg_tens30'].combine_first(df_pivot['avg_tens60'])\n",
    "df_pivot.drop(columns=['avg_tens30', 'avg_tens60'], inplace=True)\n",
    "\n",
    "\n",
    "df_pivot['med_tens'] = df_pivot['med_tens30'].combine_first(df_pivot['med_tens60'])\n",
    "df_pivot.drop(columns=['med_tens30', 'med_tens60'], inplace=True)\n",
    "\n",
    "\n",
    "df_pivot['sum_tens'] = df_pivot['sum_tens30'].combine_first(df_pivot['sum_tens60'])\n",
    "df_pivot.drop(columns=['sum_tens30', 'sum_tens60'], inplace=True)\n",
    "\n",
    "df_pivot = df_pivot.reset_index(drop=True)\n",
    "\n",
    "df = df_pivot\n",
    "df"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "58a65f1d-59fd-41c6-8143-d0a0b4e2e3d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T12:39:58.382712Z",
     "start_time": "2024-07-22T12:39:58.382163Z"
    }
   },
   "source": [
    "min_date = df['date'].min()\n",
    "max_date = df['date'].max()\n",
    "\n",
    "all_dates = pd.date_range(start=min_date, end=max_date)\n",
    "existing_dates_set = set(df['date'])\n",
    "\n",
    "missing_dates = [date.date() for date in all_dates if date.date() not in existing_dates_set]\n",
    "missing_dates"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7350ee2a-f0b8-476c-987d-53d334af9080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T12:39:58.384975Z",
     "start_time": "2024-07-22T12:39:58.384293Z"
    }
   },
   "source": [
    "# repeated_dates = np.tile(missing_dates, 16)\n",
    "\n",
    "# sensor_ids = df['group_id'].unique()\n",
    "# sensor_ids = np.repeat(sensor_ids, 3)\n",
    "\n",
    "# missing_data = pd.DataFrame({'date': repeated_dates, 'group_id': sensor_ids})\n",
    "\n",
    "# df = df.merge(missing_data, on=['date', 'group_id'], how='outer')\n",
    "# df = pd.DataFrame(df)\n",
    "# df = df.sort_values(by=['group_id', 'date']).reset_index(drop=True)\n",
    "# df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "cddfe22c-a502-4b38-8c86-77a84c2f35c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T12:39:58.386002Z",
     "start_time": "2024-07-22T12:39:58.386002Z"
    }
   },
   "source": [
    "num_missing_values = df.isna().any(axis=1).sum()\n",
    "print(\"Numero di righe con valori mancanti:\", num_missing_values)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dbb4ce2c-fc93-44e0-b6f6-c4fa310a72b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T12:39:58.388276Z",
     "start_time": "2024-07-22T12:39:58.387740Z"
    }
   },
   "source": [
    "# float_columns = df.select_dtypes(include=['float']).columns\n",
    "# df[float_columns] = df[float_columns].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "# num_missing_values = df.isna().any(axis=1).sum()\n",
    "# print(\"Numero di righe con valori mancanti:\", num_missing_values)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "832b9807-d5d4-49f5-86ce-1b298a333239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T12:39:58.389841Z",
     "start_time": "2024-07-22T12:39:58.389841Z"
    }
   },
   "source": [
    "columns_to_drop = ['min_irr', 'max_irr', 'avg_irr', 'med_irr', 'min_rain', 'avg_rain', 'sum_hum',\n",
    "                   'sum_temp', 'sum_solar', 'min_wind', 'max_wind', 'avg_wind', 'sum_wind', 'med_wind']\n",
    "df = df.drop(columns=columns_to_drop).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "group_id_mapping = {\n",
    "    '1': '72',\n",
    "    '2': '76',\n",
    "    '3': '73',\n",
    "    '4': '74',\n",
    "    '5': '61',\n",
    "    '6': '63',\n",
    "    '7': '67',\n",
    "    '8': '65',\n",
    "    '1_1': '71',\n",
    "    '2_1': '69',\n",
    "    '3_1': '75',\n",
    "    '4_1': '70',\n",
    "    '5_1': '62',\n",
    "    '6_1': '64',\n",
    "    '7_1': '68',\n",
    "    '8_1': '66'\n",
    "}\n",
    "\n",
    "df['group_id'] = df['group_id'].replace(group_id_mapping)\n",
    "df = df.rename(columns={'group_id': 'sensor_id'})\n",
    "df = df[['sensor_id', 'date', 'avg_tens'] + [col for col in df.columns if col not in ['sensor_id', 'date', 'avg_tens']]]\n",
    "df = df.sort_values(by=['sensor_id', 'date']).reset_index(drop=True)\n",
    "\n",
    "ids = df['sensor_id']\n",
    "dates = df['date']\n",
    "X = df.drop(columns=['date', 'sensor_id'])\n",
    "X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "\n",
    "X['date'] = dates\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "X = X[~X['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "X = X.drop(columns='date')\n",
    "\n",
    "y = df[['sensor_id', 'date', 'avg_tens']]\n",
    "y = y[~y['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "df_merged = pd.concat([y, X], axis=1)\n",
    "df_merged"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "33b3faa1-ca8d-44ab-abf8-c22a6b19fb24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T12:39:59.884406Z",
     "start_time": "2024-07-22T12:39:59.821856Z"
    }
   },
   "source": [
    "tens_combined = list(set(tens_all))\n",
    "tens_ordered = sorted(tens_combined, key=lambda x: int(x))\n",
    "\n",
    "\n",
    "df_cluster = df[['date', 'sensor_id', 'avg_tens']]\n",
    "df_transformed = pd.pivot_table(df_cluster, values='avg_tens', index='date', columns='sensor_id', aggfunc='mean').reset_index()\n",
    "data_array = np.array(df_transformed.T.drop('date').values)\n",
    "\n",
    "X_normalized = TimeSeriesScalerMinMax().fit_transform(data_array)\n",
    "X_flattened = X_normalized.reshape((X_normalized.shape[0], -1))\n",
    "\n",
    "n_clusters_range = range(2, 10)\n",
    "num_executions = 10\n",
    "np.random.seed(0)\n",
    "\n",
    "average_distortions = []\n",
    "\n",
    "for n_clusters in n_clusters_range:\n",
    "    distortions_for_cluster = []\n",
    "\n",
    "    for _ in range(num_executions):\n",
    "\n",
    "        seed = np.random.randint(0, 1000)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        model = TimeSeriesKMeans(n_clusters=n_clusters, metric='dtw', max_iter=10)\n",
    "        model.fit(X_normalized)\n",
    "        cluster_centers = model.cluster_centers_\n",
    "        distortion = calculate_distortion(X_flattened, cluster_centers)\n",
    "        distortions_for_cluster.append(distortion)\n",
    "\n",
    "    average_distortion = np.mean(distortions_for_cluster)\n",
    "    average_distortions.append(average_distortion)\n",
    "\n",
    "\n",
    "plt.plot(n_clusters_range, average_distortions, marker='o', label='DTW Clustering')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Distance from Centroids')\n",
    "plt.title('Select the Optimal Number of Clusters')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f8bdfee-df54-49ae-abe2-2b828ad531ab",
   "metadata": {},
   "source": [
    "model_1 = TimeSeriesKMeans(n_clusters=3, metric='dtw', max_iter=100)\n",
    "model_1.fit(data_array)\n",
    "clusters_1=model_1.predict(data_array)\n",
    "\n",
    "model_2 = TimeSeriesKMeans(n_clusters=6, metric='dtw', max_iter=100)\n",
    "model_2.fit(data_array)\n",
    "clusters_2=model_2.predict(data_array)\n",
    "\n",
    "df_cluster = pd.DataFrame({'Sensor_ID': tens_ordered, 'Cluster 1': clusters_1, 'Cluster 2': clusters_2})\n",
    "df_cluster"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f077f5-e993-40f8-bcb9-269832fb41b4",
   "metadata": {},
   "source": [
    "sensor_ids = ['72', '76', '73', '74', '61', '63', '67', '65', '71', '69', '75', '70', '62', '64', '68', '66']\n",
    "sensor_ids.sort()\n",
    "\n",
    "residuals = []\n",
    "\n",
    "for sensor in sensor_ids:\n",
    "    \n",
    "    subset = df_merged[df_merged['sensor_id'] == sensor].copy()\n",
    "    X = subset.drop(['sensor_id', 'date', 'avg_tens', 'avg_tens_lag1', 'avg_tens_lag2', 'avg_tens_lag3'], axis=1)\n",
    "    y = subset['avg_tens']\n",
    "    \n",
    "    selected_features = stepwise_bidirectional_selection(X, y, method='aic')\n",
    "    model = sm.OLS(y, sm.add_constant(X[selected_features])).fit()\n",
    "\n",
    "    intercept = model.params[0]\n",
    "    intercept_vector = np.full(3, intercept)\n",
    "\n",
    "    pred_sensor = model.predict(sm.add_constant(X[selected_features]))\n",
    "    combined_vector = np.concatenate((intercept_vector, pred_sensor))\n",
    "\n",
    "    selected_values = df.loc[df['sensor_id'] == sensor, 'avg_tens']\n",
    "    values = selected_values - combined_vector\n",
    "    res = list(zip(values))\n",
    "    \n",
    "    residuals.extend(res)\n",
    "\n",
    "\n",
    "df_residuals = pd.DataFrame(residuals, columns=['residuals'])\n",
    "\n",
    "df_residuals = df_residuals.shift(1).add_suffix('_lag1').join(df_residuals.shift(2).add_suffix('_lag2')).join(df_residuals.shift(3).add_suffix('_lag3'))\n",
    "df_residuals = pd.concat([df['date'], df_residuals], axis=1)\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "df_residuals = df_residuals[~df_residuals['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "df_residuals = df_residuals.drop(columns='date')\n",
    "\n",
    "data = pd.concat([df_merged, df_residuals], axis=1)\n",
    "data = data.drop(columns='date')\n",
    "data"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9956da63-7604-402d-9552-5974665f0c1e",
   "metadata": {},
   "source": [
    "# Main Sensors (ARIMAX top results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59c9c5-87cf-4dc7-a1ab-644a42f0dc5d",
   "metadata": {},
   "source": [
    "These are the sensors among those we focused on the most where the ARIMAX models performed the best in terms of prediction error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253225a5-8800-4b06-8ce0-310af9510b95",
   "metadata": {},
   "source": [
    "## Sensor 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48555ef2-a67a-435c-8d41-bbbd8bfb07aa",
   "metadata": {},
   "source": [
    "best_subset = ['65', '66', '69', '74']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))].reset_index(drop=True)\n",
    "df_test = data[data['sensor_id'] == '64'].reset_index(drop=True)\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1).reset_index(drop=True)\n",
    "y_train = df_train['avg_tens'].reset_index(drop=True)\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1).reset_index(drop=True)\n",
    "y_test = df_test['avg_tens'].reset_index(drop=True)\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features])).reset_index(drop=True)\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '64'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '64'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a8e64ba-8df1-4a79-9189-4c7ff264abdf",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bddad3ca-9bec-4b8e-90c3-ea3c5607c5de",
   "metadata": {},
   "source": [
    "model.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7fe4f9b-917e-4022-b56a-0aefca80fa6e",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=64,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70e36bca-1533-42e3-bbcd-7ec5383e764f",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_64.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e7b616-055b-47a5-a3f4-6eaa292c3d16",
   "metadata": {},
   "source": [
    "## Sensor 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "123923ee-922d-4fae-b983-5a72aa2cbedf",
   "metadata": {},
   "source": [
    "best_subset = ['62', '70', '71', '75']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))].reset_index(drop=True)\n",
    "df_test = data[data['sensor_id'] == '61'].reset_index(drop=True)\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1).reset_index(drop=True)\n",
    "y_train = df_train['avg_tens'].reset_index(drop=True)\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1).reset_index(drop=True)\n",
    "y_test = df_test['avg_tens'].reset_index(drop=True)\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features])).reset_index(drop=True)\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '61'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '61'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6761cedd-302c-48ea-86c1-1de3c6961e96",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3b965bc-709f-424b-ba51-6d3b09863ba9",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=61,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3720f0b8-a8f7-4a8c-987d-d5e84e32c3b7",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_61.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f99b7223-82d1-4568-9e27-6f38d717e068",
   "metadata": {},
   "source": [
    "## Sensor 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c24aa03-f6b6-45f1-8e7f-83b5f62382b1",
   "metadata": {},
   "source": [
    "best_subset = ['64', '65', '68', '69', '71']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data[data['sensor_id'] == '70']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '70'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '70'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5e79d1a-1c24-463d-b73c-f5fc17abc82e",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5889200-2c77-408f-8562-50acde982f52",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=70,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ce6fa57-6581-4a2f-972c-239485cefe66",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_70.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "aae30dbc-d13d-43e4-9468-078047d26022",
   "metadata": {},
   "source": [
    "# Main Sensors (ARIMAX is not the best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea27b5-e7cd-4def-ae41-9f085ca0523e",
   "metadata": {},
   "source": [
    "These are the sensors among those we focused on most where the ARIMAX models did not perform the best in terms of prediction error when compared to other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39fcf53-a0f2-4d25-98df-46b994843619",
   "metadata": {},
   "source": [
    "## Sensor 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7108f6e-40ee-424e-9af1-ab2d3c11724b",
   "metadata": {},
   "source": [
    "best_subset = ['61', '64']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data[data['sensor_id'] == '62']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '62'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '62'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "475d7d11-774f-4aca-bffe-b80b9e0a5953",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e4e37c2-9ae0-43b9-bb3d-86419641a096",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=62,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "381c32a5-c7dd-48db-80f2-27133a55088b",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_62.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "089ac9de-4555-4ac4-b4cf-d7f401d6cf84",
   "metadata": {},
   "source": [
    "## Sensor 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "866cb673-1f89-4d6a-bc6c-ffc5fbde41d6",
   "metadata": {},
   "source": [
    "best_subset = ['64', '67']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data[data['sensor_id'] == '63']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '63'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '63'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1715b46-6eff-4f19-b646-77d01f029987",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6e2eaf8-5a29-49da-b602-bf118fd7ff77",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=63,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9ee17b5-d5ec-42ea-b292-14ab82b00bad",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_63.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5b06e39c-c0b3-408e-bbf3-e5572663555e",
   "metadata": {},
   "source": [
    "## Sensor 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76c4fd7f-6d07-4879-abd0-a81e12831285",
   "metadata": {},
   "source": [
    "best_subset = ['68']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data[data['sensor_id'] == '67']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '67'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '67'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09f8c231-de5f-4438-b96f-f2f9dd9fb074",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc81aa5b-1e04-4bcb-a7c7-fb5acd4d0d36",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=67,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "da190b3a-b4bb-4726-92ad-fe855e8e8595",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_67.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4b59952a-f57c-4d3e-ba21-de65fe76a7b3",
   "metadata": {},
   "source": [
    "## Sensor 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3509c28-b9ba-4215-a3cf-b9b3f485525b",
   "metadata": {},
   "source": [
    "best_subset = ['67']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data[data['sensor_id'] == '68']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '68'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '68'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd8d310b-997d-4a7a-8815-e8a811abe427",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38eb8696-07f5-4f69-b454-54a386e06263",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=68,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "77da31e6-373a-461e-abe3-80bd57b4bdbc",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_68.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "87ce29cc-0614-4c6b-892f-c388d2c5a64f",
   "metadata": {},
   "source": [
    "## Sensor 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8fc96953-1679-43c1-aeff-eb4646401fe6",
   "metadata": {},
   "source": [
    "best_subset = ['62', '63', '70']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data[data['sensor_id'] == '74']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '74'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '74'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b4843ec-ae40-417d-8158-0c501bef310f",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=74,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b07ca25-aa7d-4439-888d-d6e92d4c8bcb",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_74.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "535fb49c-d322-45dc-ba1e-113c89b81513",
   "metadata": {},
   "source": [
    "## Sensor 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96109892-23be-4c5f-8ebe-e260b50f742e",
   "metadata": {},
   "source": [
    "best_subset = ['68', '73', '76']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data[data['sensor_id'] == '75']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '75'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '75'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bd3059de-9f8c-48f0-8d04-70dbedf81116",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=75,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b40c7873-99f4-4b0a-bd23-605c581a1614",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_75.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "64320d88-acb8-43f7-9d5b-9a74041260e3",
   "metadata": {},
   "source": [
    "# Other Sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee86b6d7-f9ea-4d14-b636-8f99b7aa3f90",
   "metadata": {},
   "source": [
    "## Sensor 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "babf3109-7455-4ef4-b895-463591510b3f",
   "metadata": {},
   "source": [
    "all_sensors = ['66', '69', '73', '76']\n",
    "all_subsets = list(chain.from_iterable(combinations(all_sensors, r) for r in range(1, len(all_sensors) + 1)))\n",
    "\n",
    "df_test = data[data['sensor_id'] == '65']\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "\n",
    "X_train = data[data['sensor_id'].isin(list(all_sensors))]\n",
    "ids_train = X_train[['sensor_id']].reset_index(drop=True)\n",
    "y_train = X_train[['avg_tens']].reset_index(drop=True)\n",
    "X_train = X_train.drop(columns=['sensor_id', 'avg_tens'])\n",
    "\n",
    "X_test = data[data['sensor_id'] == '65']\n",
    "ids_test = X_test[['sensor_id']].reset_index(drop=True)\n",
    "y_test = X_test[['avg_tens']].reset_index(drop=True)\n",
    "X_test = X_test.drop(columns=['sensor_id', 'avg_tens'])\n",
    "\n",
    "best_n_comp = optimize_ncomp_pls(X_train, y_train, 50, 'RMSE', 'min')\n",
    "\n",
    "pls_model = PLSRegression(n_components=best_n_comp)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pls_labels = [f'PC{i}' for i in range(1, best_n_comp + 1)]\n",
    "pls_model = PLSRegression(n_components=best_n_comp)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=pls_labels)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=pls_labels)\n",
    "\n",
    "train_pls = pd.concat([ids_train, y_train, X_train_pls], axis=1)\n",
    "test_pls = pd.concat([ids_test, y_test, X_test_pls], axis=1)\n",
    "data_pls = pd.concat([train_pls, test_pls], ignore_index=True)\n",
    "\n",
    "\n",
    "best_subset = ['66']\n",
    "\n",
    "df_train = data_pls[data_pls['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data_pls[data_pls['sensor_id'] == '65']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test))\n",
    "\n",
    "\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train)).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '65'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '65'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "pls_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a554d8a5-33b8-49b6-bc35-f7102f7dfb00",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a98bdbe7-4252-47a0-82c1-bbc20da80da4",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=65,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "378ba9f9-7e96-401c-9eb9-07e7e301b528",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_65.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e7354289-009e-4dfd-9ce9-f0344c579bd2",
   "metadata": {},
   "source": [
    "## Sensor 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1acd9cc6-1023-4850-88ce-19af44fd92e2",
   "metadata": {},
   "source": [
    "best_subset = ['65', '76']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data[data['sensor_id'] == '66']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '66'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '66'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f64c84a0-9efb-4b9d-bfa4-895f60038a9b",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e925a0c3-79c5-4007-af51-8c9d85c48b3f",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=66,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "200d845d-d5ea-40c9-82b2-7c9b214b7c09",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_66.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9c2b7604-35bf-4a85-a904-17ff3c8b3a92",
   "metadata": {},
   "source": [
    "## Sensor 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e7e1e65-448e-4ff8-b4da-77422b6261d9",
   "metadata": {},
   "source": [
    "all_sensors = ['65', '66', '73', '76']\n",
    "all_subsets = list(chain.from_iterable(combinations(all_sensors, r) for r in range(1, len(all_sensors) + 1)))\n",
    "\n",
    "df_test = data[data['sensor_id'] == '69']\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "\n",
    "X_train = data[data['sensor_id'].isin(list(all_sensors))]\n",
    "ids_train = X_train[['sensor_id']].reset_index(drop=True)\n",
    "y_train = X_train[['avg_tens']].reset_index(drop=True)\n",
    "X_train = X_train.drop(columns=['sensor_id', 'avg_tens'])\n",
    "\n",
    "X_test = data[data['sensor_id'] == '69']\n",
    "ids_test = X_test[['sensor_id']].reset_index(drop=True)\n",
    "y_test = X_test[['avg_tens']].reset_index(drop=True)\n",
    "X_test = X_test.drop(columns=['sensor_id', 'avg_tens'])\n",
    "\n",
    "best_n_comp = optimize_ncomp_pls(X_train, y_train, 50, 'RMSE', 'min')\n",
    "\n",
    "pls_model = PLSRegression(n_components=best_n_comp)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pls_labels = [f'PC{i}' for i in range(1, best_n_comp + 1)]\n",
    "pls_model = PLSRegression(n_components=best_n_comp)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=pls_labels)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=pls_labels)\n",
    "\n",
    "train_pls = pd.concat([ids_train, y_train, X_train_pls], axis=1)\n",
    "test_pls = pd.concat([ids_test, y_test, X_test_pls], axis=1)\n",
    "data_pls = pd.concat([train_pls, test_pls], ignore_index=True)\n",
    "\n",
    "\n",
    "best_subset = ['65', '76']\n",
    "\n",
    "df_train = data_pls[data_pls['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data_pls[data_pls['sensor_id'] == '69']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test))\n",
    "\n",
    "\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train)).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '69'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '69'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "pls_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c9b6065b-2fe4-478a-aa10-666a59ee79af",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0c86d3d7-277c-4a87-8352-474065f555b8",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=69,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "194cc458-8cc1-4690-a4ea-867b555119f7",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_69.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "61bd9008-7331-43cf-bdaf-83aa777a8506",
   "metadata": {},
   "source": [
    "## Sensor 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d3ac8bcf-68a5-4530-af3f-147749a98702",
   "metadata": {},
   "source": [
    "best_subset = ['61', '64', '70']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data[data['sensor_id'] == '71']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '71'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '71'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4eadbe6e-7a03-482f-a316-f316d6c783b0",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c44da870-cd8b-4ee5-9712-a4dbaa29008b",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=71,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7dfdf783-84dc-4048-ae4e-4c2672b59d9e",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_71.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4d38cd87-0ab1-491a-a165-1a171298101b",
   "metadata": {},
   "source": [
    "## Sensor 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0106825e-5e10-4fab-a3d9-8856a3a3da50",
   "metadata": {},
   "source": [
    "best_subset = ['62', '67', '68', '71']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data[data['sensor_id'] == '72']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '72'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '72'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "862a9b06-a71d-4c24-b690-54356c1da6d7",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7a4d764d-b37b-4358-9fbf-31b317cec691",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=72,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6acabaf3-5a0d-4247-87c8-7e58be10a4e1",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_72.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "57e8b481-4342-4ceb-9b69-2a26bbe3c92c",
   "metadata": {},
   "source": [
    "## Sensor 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e1499d8-b73c-42cc-95da-c4ceb1111d95",
   "metadata": {},
   "source": [
    "best_subset = ['65', '66', '75', '76']\n",
    "\n",
    "df_train = data[data['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data[data['sensor_id'] == '73']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train[selected_features])).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '73'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '73'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "selected_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd829fcf-60c5-408b-a58d-2435612e58cf",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d777f3ad-bc36-4139-b132-8f4e072c99fd",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=73,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9f8b4752-b77a-45ce-8e32-b5ba93aea5c7",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_73.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4b2fdd7c-dadc-4ba2-8165-139c0d14b987",
   "metadata": {},
   "source": [
    "## Sensor 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e28238d5-1fa5-4f72-83a8-2e6e3b7b2e5d",
   "metadata": {},
   "source": [
    "all_sensors = ['65', '66', '69', '73']\n",
    "all_subsets = list(chain.from_iterable(combinations(all_sensors, r) for r in range(1, len(all_sensors) + 1)))\n",
    "\n",
    "df_test = data[data['sensor_id'] == '76']\n",
    "y_baseline = df_test['avg_tens_lag1'].reset_index(drop=True)\n",
    "\n",
    "X_train = data[data['sensor_id'].isin(list(all_sensors))]\n",
    "ids_train = X_train[['sensor_id']].reset_index(drop=True)\n",
    "y_train = X_train[['avg_tens']].reset_index(drop=True)\n",
    "X_train = X_train.drop(columns=['sensor_id', 'avg_tens'])\n",
    "\n",
    "X_test = data[data['sensor_id'] == '76']\n",
    "ids_test = X_test[['sensor_id']].reset_index(drop=True)\n",
    "y_test = X_test[['avg_tens']].reset_index(drop=True)\n",
    "X_test = X_test.drop(columns=['sensor_id', 'avg_tens'])\n",
    "\n",
    "best_n_comp = optimize_ncomp_pls(X_train, y_train, 50, 'RMSE', 'min')\n",
    "\n",
    "pls_model = PLSRegression(n_components=best_n_comp)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pls_labels = [f'PC{i}' for i in range(1, best_n_comp + 1)]\n",
    "pls_model = PLSRegression(n_components=best_n_comp)\n",
    "pls_model.fit(X_train, y_train)\n",
    "\n",
    "X_train_pls = pls_model.transform(X_train)\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=pls_labels)\n",
    "X_test_pls = pls_model.transform(X_test)\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=pls_labels)\n",
    "\n",
    "train_pls = pd.concat([ids_train, y_train, X_train_pls], axis=1)\n",
    "test_pls = pd.concat([ids_test, y_test, X_test_pls], axis=1)\n",
    "data_pls = pd.concat([train_pls, test_pls], ignore_index=True)\n",
    "\n",
    "\n",
    "best_subset = ['66', '69', '73']\n",
    "\n",
    "df_train = data_pls[data_pls['sensor_id'].isin(list(best_subset))]\n",
    "df_test = data_pls[data_pls['sensor_id'] == '76']\n",
    "\n",
    "X_train = df_train.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_train = df_train['avg_tens']\n",
    "\n",
    "X_test = df_test.drop(['sensor_id', 'avg_tens'], axis=1)\n",
    "y_test = df_test['avg_tens']\n",
    "\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "pred_sensor = model.predict(sm.add_constant(X_test))\n",
    "\n",
    "\n",
    "y_train_plot = y_train.reset_index(drop=True)\n",
    "pred_train = model.predict(sm.add_constant(X_train)).reset_index(drop=True)\n",
    "\n",
    "y_test_plot = y_test.reset_index(drop=True)\n",
    "pred_test = pred_sensor.reset_index(drop=True)\n",
    "\n",
    "irrigation_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_irr']]\n",
    "rain_train = df[df['sensor_id'].isin(list(best_subset))][['date', 'sum_rain']]\n",
    "\n",
    "dates_to_remove = [datetime.date(2023, 4, 28), datetime.date(2023, 4, 29), datetime.date(2023, 4, 30)]\n",
    "irrigation_train = irrigation_train[~irrigation_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_train = rain_train[~rain_train['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_train = irrigation_train['sum_irr']\n",
    "rain_train = rain_train['sum_rain']\n",
    "\n",
    "irrigation_test = df[df['sensor_id'] == '69'][['date', 'sum_irr']].reset_index(drop=True)\n",
    "rain_test = df[df['sensor_id'] == '69'][['date', 'sum_rain']].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test[~irrigation_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "rain_test = rain_test[~rain_test['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "\n",
    "irrigation_test = irrigation_test['sum_irr']\n",
    "rain_test = rain_test['sum_rain']\n",
    "\n",
    "\n",
    "pls_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "46b9ef05-9a1f-4590-a58f-349d9671beb7",
   "metadata": {},
   "source": [
    "r_squared_arimax = round(r_squared(y_test, pred_sensor), 3)\n",
    "mape_arimax = round(mape(y_test, pred_sensor), 3)\n",
    "mape_std_arimax = round(mape_std(y_test, pred_sensor), 3)\n",
    "mae_arimax = round(mae(y_test, pred_sensor), 3)\n",
    "rmse_arimax = round(rmse(y_test, pred_sensor), 3)\n",
    "rmse_std_arimax = round(rmse_std(y_test, pred_sensor), 3)\n",
    "\n",
    "\n",
    "table = [\n",
    "    ['Metric', 'ARIMAX'],\n",
    "    ['R-squared', r_squared_arimax],\n",
    "    ['MAPE', mape_arimax],\n",
    "    ['MAPE_std', mape_std_arimax],\n",
    "    ['MAE', mae_arimax],\n",
    "    ['RMSE', rmse_arimax],\n",
    "    ['RMSE_std', rmse_std_arimax]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "acf1c05c-b2d8-4fdb-8f53-045b9dcfe504",
   "metadata": {},
   "source": [
    "show_figure(sensor_target_id=76,\n",
    "            y_baseline=y_baseline,\n",
    "            y_train=y_train_plot,\n",
    "            y_pred=pred_train,\n",
    "            y_test=y_test_plot,\n",
    "            y_predictions=pred_test,\n",
    "            irrigation_train=irrigation_train,\n",
    "            rain_train=rain_train,\n",
    "            irrigation_test=irrigation_test,\n",
    "            rain_test=rain_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "039a9bd3-cfb7-4c4a-baf4-c492dd7b0a3b",
   "metadata": {},
   "source": [
    "file_path = os.path.join('predictions', 'sensor_76.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(pred_sensor, file)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
