{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72e8fc2-3917-429c-8fb5-e31a0c42f9b1",
   "metadata": {},
   "source": [
    "# Decision Support System for Irrigation"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b275e79-669c-4bec-ae39-9a03d5a5346b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T13:45:53.132175Z",
     "start_time": "2024-11-06T13:45:51.492320Z"
    }
   },
   "source": [
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pickle\n",
    "\n",
    "from fuzzy_expert.variable import FuzzyVariable\n",
    "from fuzzy_expert.rule import FuzzyRule\n",
    "from fuzzy_expert.inference import DecompositionalInference\n",
    "from retry_requests import retry\n",
    "from datetime import date, timedelta\n",
    "from scipy.stats import linregress\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "eb23d1a0-0a09-4cd1-a2dd-4243a67e3659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:12:11.551700Z",
     "start_time": "2024-06-17T12:12:11.531820Z"
    }
   },
   "source": [
    "def pre_processing(data):\n",
    "\n",
    "    # Columns Selection and Formatting\n",
    "    \n",
    "    df_rovere = data[['reading_id', 'timestamp', 'sensor_id', 'value', 'description', 'group_id']].copy()\n",
    "    df_rovere[['reading_id', 'sensor_id', 'description', 'group_id']] = df_rovere[['reading_id', 'sensor_id', 'description', 'group_id']].astype(str)\n",
    "    df_rovere['timestamp'] = pd.to_datetime(df_rovere['timestamp']).dt.floor('D').dt.date\n",
    "    df_rovere['value'] = df_rovere['value'].astype(float)\n",
    "\n",
    "    tens_30 = ['72', '76', '73', '74', '61', '63', '67', '65']\n",
    "    tens_60 = ['71', '69', '75', '70', '62', '64', '68', '66']\n",
    "    tens_all = tens_30 + tens_60\n",
    "    \n",
    "    df_rovere.loc[df_rovere['description'] == 'tensiometer', 'description'] = 'Tensiometer'\n",
    "    df_rovere.loc[df_rovere['description'] == 'irrigation', 'description'] = 'Irrigation'\n",
    "\n",
    "    \n",
    "    # Duplication\n",
    "    \n",
    "    condition_not_in_list = ~df_rovere['sensor_id'].isin(tens_30)\n",
    "    df_dup = df_rovere[condition_not_in_list]\n",
    "    df_dup['group_id'] = df_dup['group_id'] + '_dup'\n",
    "\n",
    "    df_rovere = df_rovere[~df_rovere['sensor_id'].isin(tens_60)]\n",
    "    df_rovere = pd.concat([df_rovere, df_dup], ignore_index=True)\n",
    "    df_rovere.sort_values(by=['group_id', 'timestamp'], inplace=True)\n",
    "    df_rovere.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \n",
    "    # Grouping and Creation of Summary Values\n",
    "    \n",
    "    df_group = df_rovere.groupby(['timestamp', 'description', 'sensor_id', 'group_id']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "    df_group.columns = ['timestamp', 'description', 'sensor_id', 'group_id', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "    \n",
    "    # Pivoting\n",
    "    \n",
    "    df_pivot = df_group.pivot(index=['timestamp', 'group_id'], columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "    df_pivot.columns = ['date', 'group_id'] + [f\"{agg}_{feature}\" for agg in ['min', 'max', 'avg', 'med', 'sum'] for feature in ['hum', 'temp', 'solar', 'wind', 'irr', 'rain', 'tens']]\n",
    "\n",
    "    df = df_pivot.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    # Sensor ID Mapping\n",
    "    \n",
    "    group_id_mapping = {str(i): str(j) for i, j in zip(range(1, 9), tens_30)}\n",
    "    group_id_mapping.update({str(i) + '_dup': str(j) for i, j in zip(range(1, 9), tens_60)})\n",
    "    df['group_id'] = df['group_id'].replace(group_id_mapping)\n",
    "    df = df.rename(columns={'group_id': 'sensor_id'})\n",
    "\n",
    "    df = df[['sensor_id', 'date', 'avg_tens', 'max_temp', 'avg_hum', 'avg_solar', 'sum_rain', 'sum_irr']]\n",
    "    df = df[['sensor_id', 'date', 'avg_tens'] + [col for col in df.columns if col not in ['sensor_id', 'date', 'avg_tens']]]\n",
    "    df = df.sort_values(by=['sensor_id', 'date']).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    # Imputation of Missing Values\n",
    "    \n",
    "    float_columns = df.select_dtypes(include=['float']).columns\n",
    "    df[float_columns] = df[float_columns].interpolate(method='linear', limit_direction='both')\n",
    "    \n",
    "\n",
    "    # Shifting Values using the previous 3 Days\n",
    "    \n",
    "    ids = df['sensor_id']\n",
    "    dates = df['date']\n",
    "    X = df.drop(columns=['date', 'sensor_id'])\n",
    "    X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "    \n",
    "    X['date'] = dates\n",
    "    dates_to_remove = [date(2023, 4, 28), date(2023, 4, 29), date(2023, 4, 30)]\n",
    "    X = X[~X['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "    X = X.drop(columns='date')\n",
    "    \n",
    "    y = df[['sensor_id', 'date', 'avg_tens']]\n",
    "    y = y[~y['date'].isin(dates_to_remove)].reset_index(drop=True)\n",
    "    \n",
    "    df_merged = pd.concat([y, X], axis=1)\n",
    "    df = df_merged[df_merged['sensor_id'].isin(tens_30)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def pre_processing_target(sensor_id, target, sensors_mean):\n",
    "    \n",
    "    df_rovere = target.copy()\n",
    "    sensor_id = str(sensor_id)\n",
    "\n",
    "    \n",
    "    # Formatting\n",
    "    \n",
    "    df_rovere['timestamp'] = pd.to_datetime(df_rovere['timestamp']).dt.floor('D').dt.date    \n",
    "    df_rovere['sensor_id'] = df_rovere['sensor_id'].astype(str)\n",
    "    df_rovere['value'] = df_rovere['value'].astype(float)\n",
    "    df_rovere['description'] = df_rovere['description'].astype(str)\n",
    "\n",
    "    df_rovere = df_rovere.sort_values(by=['timestamp', 'description']).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    # Grouping and Creation of Summary Values\n",
    "    \n",
    "    df_group = df_rovere.groupby(['timestamp', 'description', 'sensor_id']).agg({'value': ['min', 'max', 'mean', 'median', 'sum']}).reset_index()\n",
    "    df_group.columns = ['timestamp', 'description', 'sensor_id', 'val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']\n",
    "\n",
    "    \n",
    "    # Pivoting\n",
    "    \n",
    "    df_pivot = df_group.pivot(index=['timestamp'], columns='description', values=['val_min', 'val_max', 'val_avg', 'val_med', 'val_sum']).reset_index()\n",
    "    df_pivot.columns.name = None\n",
    "\n",
    "    if df_pivot.shape[1] == 36:\n",
    "        df_pivot.columns = ['date'] + [f\"{agg}_{feature}\" for agg in ['min', 'max', 'avg', 'med', 'sum'] for feature in ['hum', 'temp', 'solar', 'wind', 'irr', 'rain', 'tens']]\n",
    "        \n",
    "    elif df_pivot.shape[1] == 31:\n",
    "        df_pivot.columns = ['date'] + [f\"{agg}_{feature}\" for agg in ['min', 'max', 'avg', 'med', 'sum'] for feature in ['hum', 'temp', 'solar', 'irr', 'rain', 'tens']]\n",
    "        \n",
    "    else:\n",
    "        print('Error: The Number of Features is not Correct')\n",
    "\n",
    "    columns_to_drop = ['min_irr', 'max_irr', 'avg_irr', 'med_irr', 'min_rain', 'avg_rain', 'sum_hum', 'sum_temp', 'sum_solar', 'min_wind', 'max_wind', 'avg_wind', 'sum_wind', 'med_wind']\n",
    "    columns_present = [col for col in columns_to_drop if col in df_pivot.columns]\n",
    "    \n",
    "    if columns_present:\n",
    "        df = df_pivot.drop(columns=columns_present).reset_index(drop=True)\n",
    "        \n",
    "    else:\n",
    "        df = df_pivot.copy()\n",
    "\n",
    "    df = df[['date', 'avg_tens'] + [col for col in df.columns if col not in ['sensor_id', 'date', 'avg_tens']]]\n",
    "\n",
    "    \n",
    "    # Creates a Row for the next day's observation\n",
    "    \n",
    "    y = df['avg_tens']\n",
    "    #y = y[-3:].reset_index(drop=True)\n",
    "    last_date = df['date'].iloc[-1]\n",
    "    target_date = last_date + timedelta(days=1)\n",
    "    new_obs = [target_date] + [np.nan] * (len(df.columns) - 1)\n",
    "    df.loc[len(df)] = new_obs\n",
    "\n",
    "    X = df.drop(columns=['date'])\n",
    "    X = X.shift(1).add_suffix('_lag1').join(X.shift(2).add_suffix('_lag2')).join(X.shift(3).add_suffix('_lag3'))\n",
    "    X_target = pd.DataFrame(X.iloc[-1]).transpose().reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    # Computation of Residuals\n",
    "    \n",
    "    y_mean = sensors_mean.loc[sensors_mean['sensor_id'] == sensor_id, 'sensor_mean'].values[0]\n",
    "    predict_lm = [y_mean] * 3\n",
    "\n",
    "    # Using more than 3 days\n",
    "    #selected_features = stepwise_bidirectional_selection(X_train, y_train, method='aic')\n",
    "    #model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "    #predict_lm =  model.predict(sm.add_constant(X[selected_features]))\n",
    "\n",
    "    residuals = y - predict_lm\n",
    "    residuals = np.append(residuals, np.nan)\n",
    "    df_residuals = pd.DataFrame(residuals, columns=['residuals'])\n",
    "    df_residuals = df_residuals.shift(1).add_suffix('_lag1').join(df_residuals.shift(2).add_suffix('_lag2')).join(df_residuals.shift(3).add_suffix('_lag3'))\n",
    "    last_row_res = df_residuals.iloc[-1].to_frame().transpose().reset_index(drop=True)\n",
    "\n",
    "    X_target = pd.concat([X_target, last_row_res], axis=1).sort_index(axis=1)\n",
    "\n",
    "    return X_target\n",
    "\n",
    "\n",
    "def plot_temp_analysis(df, target_feature, feature_name):\n",
    "\n",
    "    df_target = df[target_feature]\n",
    "    \n",
    "    plt.figure(figsize=(20, 6))\n",
    "\n",
    "    \n",
    "    # Plot 1: Histogram of the Feature of Interest\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist(df_target, bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.title('Distribution of ' + feature_name)\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True)\n",
    "\n",
    "    \n",
    "    # Plot 2: Time Series of the Feature of Interest\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    df_sensor_61 = df[df['sensor_id'] == '61']\n",
    "    plt.plot(df_sensor_61['date'], df_sensor_61[target_feature], linestyle='-', label=feature_name, color='#636EFA')\n",
    "    plt.title(feature_name + ' Time Series')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    locator = mdates.MonthLocator(bymonthday=1)\n",
    "    formatter = mdates.DateFormatter('%b')\n",
    "    plt.gca().xaxis.set_major_locator(locator)\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    # Plot 3: Scatterplot between the Feature of Interest and Tensiometer with Lineare Regression line\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(df_target, df['avg_tens'])\n",
    "    line = slope * df_target + intercept\n",
    "    plt.scatter(df_target, df['avg_tens'], color='green', alpha=0.5, label='Data Points')\n",
    "    plt.plot(df_target, line, color='red', label='Regression Line')\n",
    "    plt.title(feature_name + ' and Tensiometer Scatterplot')\n",
    "    plt.xlabel(feature_name + ' of the Previous Day')\n",
    "    plt.ylabel('Avg Tensiometer Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plotting\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def fuzzy_decision(decision_defuzzy):\n",
    "    if decision_defuzzy <= 0.5:\n",
    "        return 'Not Recommended'\n",
    "    elif 0.5 < decision_defuzzy <= 1.5:\n",
    "        return 'Half Turn'\n",
    "    elif 1.5 < decision_defuzzy <= 2.5:\n",
    "        return 'Single Turn'\n",
    "    else:\n",
    "        return 'Double Turn'\n",
    "\n",
    "\n",
    "def demo(current_avg_tensiometer, predicted_avg_tensiometer, predicted_rain_amount, predicted_max_temperature):\n",
    "    plt.figure(figsize=(25,15))\n",
    "    model.plot(\n",
    "        variables=fuzzy_variables,\n",
    "        rules=fuzzy_rules,\n",
    "        current_avg_tensiometer=current_avg_tensiometer,\n",
    "        predicted_avg_tensiometer=predicted_avg_tensiometer,\n",
    "        predicted_rain_amount=predicted_rain_amount,\n",
    "        predicted_max_temperature=predicted_max_temperature,\n",
    ")\n",
    "    \n",
    "# def compute_indicators(data):\n",
    "    \n",
    "#     indicators_df = pd.DataFrame(data).copy()\n",
    "#     indicators_df['sum_rain_tom'] = indicators_df['sum_rain_tom'].apply(lambda x: 0 if x <= 5 else (1 if x <= 10 else 2))\n",
    "#     indicators_df['max_probrain_tom'] = indicators_df['max_probrain_tom'].apply(lambda x: 0 if x <= 40 else (1 if x <= 80 else 2))\n",
    "#     indicators_df['avg_temp_tom'] = indicators_df['avg_temp_tom'].apply(lambda x: 0 if x <= 17.5 else (1 if x <= 22.5 else 2))\n",
    "#     indicators_df['avg_hum_tom'] = indicators_df['avg_hum_tom'].apply(lambda x: 0 if x <= 60 else (1 if x <= 80 else 2))\n",
    "#     indicators_df['avg_solar_tom'] = indicators_df['avg_solar_tom'].apply(lambda x: 0 if x <= 100 else (1 if x <= 300 else 2))\n",
    "\n",
    "#     indicators = pd.DataFrame({\n",
    "#         'tensiometer': (indicators_df['avg_tens_actual'] + indicators_df['avg_tens_trend']).astype(int),\n",
    "#         'actual_water': (indicators_df['sum_rain_3_days'] + indicators_df['sum_irr_3_days']).astype(int),\n",
    "#         'predicted_water': indicators_df['sum_rain_tom'] + indicators_df['max_probrain_tom'],\n",
    "#         'other_factors': indicators_df['avg_temp_tom'] + indicators_df['avg_hum_tom'] + indicators_df['avg_solar_tom']\n",
    "#     })\n",
    "    \n",
    "#     return indicators"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "489d0da2-26db-48f5-9ff6-4b09766b0403",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "bb4b9eea-c432-4b6c-96d6-28033f3ea78d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:12:18.107974Z",
     "start_time": "2024-06-17T12:12:15.145057Z"
    }
   },
   "source": [
    "df = pd.read_json('row_data_rovere.json')\n",
    "df = pre_processing(df)\n",
    "df"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71f686a-7088-4c3b-95cc-6c423951ef72",
   "metadata": {},
   "source": [
    "selected_columns = df.drop(columns=['sensor_id', 'date'])\n",
    "\n",
    "corr_mat = selected_columns.corr()\n",
    "corr_mat.sort_values(by='avg_tens', axis=0, ascending=False, inplace=True)\n",
    "corr_mat.sort_values(by='avg_tens', axis=1, ascending=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(40, 6))\n",
    "sns.heatmap(corr_mat, annot=True, cmap='coolwarm', vmin=-1, vmax=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d89f8f-83b1-48fc-b0c7-394c1872df62",
   "metadata": {},
   "source": [
    "plot_temp_analysis(df, 'max_temp_lag1', 'Temperature')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d66947-a682-474a-a21a-6573e0801d8a",
   "metadata": {},
   "source": [
    "plot_temp_analysis(df, 'avg_hum_lag1', 'Avg Air Humidity')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33ac7e8e-4614-4f23-8166-9daa4cc5c142",
   "metadata": {},
   "source": [
    "plot_temp_analysis(df, 'avg_solar_lag1', 'Avg Solar Radiation')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ecc9085-e85e-4c09-b898-9ccfdc44a3a8",
   "metadata": {},
   "source": [
    "plot_temp_analysis(df, 'sum_rain_lag1', 'Accumulated Rain')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de730d81-2b24-4d39-9edf-08b5fdbe592a",
   "metadata": {},
   "source": [
    "plot_temp_analysis(df, 'sum_irr_lag1', 'Sum Irrigation')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "25a75151-9ad5-42cf-8354-5d7767771058",
   "metadata": {},
   "source": [
    "## Fuzzy System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91c52b2c-d5a5-4581-b8ed-aecf69fd5886",
   "metadata": {},
   "source": [
    "excel_file = 'dss_rules.xlsx'\n",
    "sheet_name = 'Rules'\n",
    "\n",
    "rules_df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "rules_df = rules_df.iloc[:, :-1].rename(columns=lambda x: x.lower().replace(' ', '_'))\n",
    "\n",
    "rules_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a66b1476-dfee-473f-919a-4fbc8489f8a2",
   "metadata": {},
   "source": [
    "sheet_name = 'Crispy Values'\n",
    "\n",
    "crispy_df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "crispy_input = crispy_df.iloc[:, 0].dropna().values\n",
    "crispy_output = crispy_df.iloc[:, 1].dropna().values\n",
    "\n",
    "print(crispy_input)\n",
    "print(crispy_output)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa4b2a59-297e-4f48-85f9-0f30c09744fd",
   "metadata": {},
   "source": [
    "sheet_name = 'Fuzzy Values'\n",
    "\n",
    "fuzzy_df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "fuzzy_df = fuzzy_df.iloc[:, 1:].rename(columns=lambda x: x.lower().replace(' ', '_'))\n",
    "\n",
    "fuzzy_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "357956ae-4462-4261-a7e1-66f2432ab7ae",
   "metadata": {},
   "source": [
    "# Fuzzy Variables Definition\n",
    "\n",
    "fuzzy_variables = {}\n",
    "n_features = int(rules_df.shape[1])\n",
    "\n",
    "for i in range(n_features):\n",
    "    \n",
    "    key = rules_df.columns.tolist()[i]\n",
    "\n",
    "    min = fuzzy_df.iloc[0, i]\n",
    "    max = fuzzy_df.iloc[1, i]\n",
    "    n_classes = int(fuzzy_df.iloc[2, i])\n",
    "    fraction_range = (max - min) / (n_classes-1)\n",
    "    universe_range = (min-2*fraction_range, max+2*fraction_range)\n",
    "    \n",
    "    terms = {}\n",
    "    \n",
    "    if i != n_features-1:\n",
    "        crispy = crispy_input\n",
    "        \n",
    "    else:\n",
    "        crispy = crispy_output\n",
    "    \n",
    "    for j in range(n_classes):\n",
    "        \n",
    "        if j == 0:\n",
    "            terms[crispy[j]] = [(min, 1), (min+fraction_range, 0)]\n",
    "            \n",
    "        elif j == n_classes-1:\n",
    "            terms[crispy[j]] = [(max-fraction_range, 0), (max, 1)]\n",
    "            \n",
    "        else:\n",
    "            terms[crispy[j]] = [(min+(j-1)*fraction_range, 0), (min+j*fraction_range, 1), (min+(j+1)*fraction_range, 0)]\n",
    "    \n",
    "    value = FuzzyVariable(universe_range=universe_range, terms=terms)\n",
    "    fuzzy_variables[key] = value\n",
    "\n",
    "\n",
    "# Plots of Fuzzy Variables\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "num_plots = len(fuzzy_variables)\n",
    "num_cols = 2\n",
    "num_rows = math.ceil(len(fuzzy_variables) / num_cols)\n",
    "\n",
    "for i, (key, value) in enumerate(fuzzy_variables.items(), 1):\n",
    "    plt.subplot(num_rows, num_cols, i)\n",
    "    value.plot()\n",
    "    plt.title(key)\n",
    "    plt.xlabel('Universe Range')\n",
    "    plt.ylabel('Fuzzy Value')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "800cbd37-95a2-4f46-bec3-254c744b0c09",
   "metadata": {},
   "source": [
    "# Fuzzy Rules Definition\n",
    "\n",
    "fuzzy_rules = []\n",
    "n_rules = rules_df.shape[0]\n",
    "n_features = rules_df.shape[1]\n",
    "\n",
    "for i in range(n_rules):\n",
    "\n",
    "    input_variables = []\n",
    "    output_variable = []\n",
    "    \n",
    "    for j in range(n_features):\n",
    "\n",
    "        if j == 0:\n",
    "            term = (rules_df.columns.tolist()[j], rules_df.iloc[i, j])\n",
    "            input_variables.append(term)\n",
    "\n",
    "        elif j == n_features-1:\n",
    "            term = (rules_df.columns.tolist()[j], rules_df.iloc[i, j])\n",
    "            output_variable.append(term)\n",
    "\n",
    "        elif not pd.isna(rules_df.iloc[i, j]):\n",
    "            term = ('AND', rules_df.columns.tolist()[j], rules_df.iloc[i, j])\n",
    "            input_variables.append(term)\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    rule = FuzzyRule(premise = input_variables, consequence = output_variable)\n",
    "    fuzzy_rules.append(rule)\n",
    "\n",
    "\n",
    "# Fuzzy Model Definition\n",
    "\n",
    "model = DecompositionalInference(\n",
    "    and_operator='min',\n",
    "    or_operator='max',\n",
    "    implication_operator='Rc',\n",
    "    composition_operator='max-min',\n",
    "    production_link='max',\n",
    "    defuzzification_operator='cog',\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "41bba010-fa47-4b2d-86d6-9c1d91f6ecb4",
   "metadata": {},
   "source": [
    "## Fuzzy Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744c4d70-866e-4ff5-b6d9-b8ae09969ab3",
   "metadata": {},
   "source": [
    "### Example 1: Recommendation with manually Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736ca03-0f9b-46bf-9a06-52d1c01516e4",
   "metadata": {},
   "source": [
    "Case 1: Medium Current Tensiometer Value (300) & Predicted (320), No Rain Predicted, Medium Max Temperature Predicted (23 degrees) -> Irrigation Not Recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7581f9cf-5e3e-4d39-bcce-c59a160b035b",
   "metadata": {},
   "source": [
    "decision = model(\n",
    "    variables=fuzzy_variables,\n",
    "    rules=fuzzy_rules,\n",
    "    current_avg_tensiometer=300,\n",
    "    predicted_avg_tensiometer=320,\n",
    "    predicted_rain_amount=0,\n",
    "    predicted_max_temperature=25,\n",
    ")\n",
    "\n",
    "decision_defuzzy = round(decision[0]['decision'], 3)\n",
    "decision_fuzzy = fuzzy_decision(decision_defuzzy)\n",
    "\n",
    "print('Numerical Value:', decision_defuzzy)\n",
    "print('Fuzzy Value:', decision_fuzzy) "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "61153cee-71e9-4603-a47e-08ffd2ccb392",
   "metadata": {},
   "source": [
    "Case 2: High Current Tensiometer Value (380), Medium Predicted Tensiometer Value (320), Medium Predicted Rain Amount (10mm), High Temperature (30 degrees) -> Half Turn Recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6882406-9c47-4c33-bd2f-fee2cd2f2e35",
   "metadata": {},
   "source": [
    "decision = model(\n",
    "    variables=fuzzy_variables,\n",
    "    rules=fuzzy_rules,\n",
    "    current_avg_tensiometer=380,\n",
    "    predicted_avg_tensiometer=320,\n",
    "    predicted_rain_amount=10,\n",
    "    predicted_max_temperature=30,\n",
    ")\n",
    "\n",
    "decision_defuzzy = round(decision[0]['decision'], 3)\n",
    "decision_fuzzy = fuzzy_decision(decision_defuzzy)\n",
    "\n",
    "print('Numerical Value:', decision_defuzzy)\n",
    "print('Fuzzy Value:', decision_fuzzy) "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "402cb850-5879-4de7-9dcf-6dc69e656796",
   "metadata": {},
   "source": [
    "Case 3: Medium Current Tensiometer Value (320), High Predicted Tensiometer Value (380), No Rain Predicted, High Temperature (30 degrees) -> Single Turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f14fe4e6-d610-457f-aca2-782a784c5efa",
   "metadata": {},
   "source": [
    "decision = model(\n",
    "    variables=fuzzy_variables,\n",
    "    rules=fuzzy_rules,\n",
    "    current_avg_tensiometer=320,\n",
    "    predicted_avg_tensiometer=380,\n",
    "    predicted_rain_amount=0,\n",
    "    predicted_max_temperature=30,\n",
    ")\n",
    "\n",
    "decision_defuzzy = round(decision[0]['decision'], 3)\n",
    "decision_fuzzy = fuzzy_decision(decision_defuzzy)\n",
    "\n",
    "print('Numerical Value:', decision_defuzzy)\n",
    "print('Fuzzy Value:', decision_fuzzy) "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "99c7bb64-9ca4-4af5-a334-b4d92d267262",
   "metadata": {},
   "source": [
    "Case 4: High Current & Predicted Tensiometer Value (380), No Rain Predicted, High Temperature (30 degrees) -> Double Turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af7aef9c-92e7-4b2c-bd5d-73e50994a852",
   "metadata": {},
   "source": [
    "decision = model(\n",
    "    variables=fuzzy_variables,\n",
    "    rules=fuzzy_rules,\n",
    "    current_avg_tensiometer=380,\n",
    "    predicted_avg_tensiometer=380,\n",
    "    predicted_rain_amount=0,\n",
    "    predicted_max_temperature=30,\n",
    ")\n",
    "\n",
    "decision_defuzzy = round(decision[0]['decision'], 3)\n",
    "decision_fuzzy = fuzzy_decision(decision_defuzzy)\n",
    "\n",
    "print('Numerical Value:', decision_defuzzy)\n",
    "print('Fuzzy Value:', decision_fuzzy) "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9f0ea9a-d598-4d77-90d6-e60cf6682fcb",
   "metadata": {},
   "source": [
    "# All Cases\n",
    "\n",
    "interact(\n",
    "    demo,\n",
    "    current_avg_tensiometer=widgets.FloatSlider(min=0, max=600),\n",
    "    predicted_avg_tensiometer=widgets.FloatSlider(min=0, max=600),\n",
    "    predicted_rain_amount=widgets.FloatSlider(min=0, max=30),\n",
    "    predicted_max_temperature=widgets.FloatSlider(min=0, max=40),\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "061f8cb4-5549-4acd-8270-74cbc500e71a",
   "metadata": {},
   "source": [
    "### Example 2: Recommendation with Tensiometer Value Forecasting (based on an ARIMAX model) & Forecasting Data from OpenMeteo's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d778379-5b1f-4c77-9520-100aa79f32dd",
   "metadata": {},
   "source": [
    "# Current & Predicted Tensiometer Value\n",
    "\n",
    "with open('models/75-arimax_aic-model.pkl', 'rb') as f:\n",
    "    model_aic_75 = pickle.load(f)\n",
    "\n",
    "with open('models/75-arimax_aic-fs.pkl', 'rb') as f:\n",
    "    fs_aic_75 = pickle.load(f)\n",
    "\n",
    "with open('sensors_mean.pkl', 'rb') as f:\n",
    "    sensors_mean = pickle.load(f)\n",
    "\n",
    "target_example = pd.read_json('target_example.json')\n",
    "X_target = pre_processing_target(75, target_example, sensors_mean)\n",
    "X_target['const'] = 1.0\n",
    "\n",
    "current_avg_tensiometer = X_target['avg_tens_lag1'].iloc[0]\n",
    "predicted_avg_tensiometer = model_aic_75.predict(X_target[['const'] + fs_aic_75])[0]\n",
    "\n",
    "\n",
    "# Weather Forecasting Data (Rain Amount & Max Temperature)\n",
    "\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "params = {\n",
    "\t'latitude': 46.245079,\n",
    "\t'longitude': 11.164434,\n",
    "\t'hourly': ['rain', 'temperature_2m', 'relative_humidity_2m'],\n",
    "\t'timezone': 'auto',\n",
    "\t'start_date': '2024-02-29',\n",
    "\t'end_date': '2024-03-03'\n",
    "}\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "response = responses[0]\n",
    "#print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "#print(f\"Elevation {response.Elevation()} m asl\")\n",
    "#print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "#print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "hourly = response.Hourly()\n",
    "hourly_rain = hourly.Variables(0).ValuesAsNumpy()\n",
    "hourly_temperature_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "#hourly_relative_humidity_2m = hourly.Variables(2).ValuesAsNumpy()\n",
    "\n",
    "df_forecast = pd.DataFrame()\n",
    "df_forecast['date'] = pd.date_range(\n",
    "\tstart = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")\n",
    "df_forecast['date'] = df_forecast['date'].dt.date\n",
    "\n",
    "df_forecast['predicted_rain_amount'] = hourly_rain.astype(float)\n",
    "df_forecast['predicted_max_temperature'] = hourly_temperature_2m.astype(float)\n",
    "#df_forecast['predicted_air_humidity'] = hourly_relative_humidity_2m.astype(float)\n",
    "\n",
    "first_date = df_forecast['date'].iloc[0]\n",
    "last_date = df_forecast['date'].iloc[-1]\n",
    "rows_to_drop = df_forecast[(df_forecast['date'] == first_date) | (df_forecast['date'] == last_date)].index\n",
    "df_forecast = df_forecast.drop(rows_to_drop).reset_index(drop=True)\n",
    "df_forecast = df_forecast.drop(columns=['date'])\n",
    "\n",
    "predicted_rain_amount = df_forecast['predicted_rain_amount'].sum()\n",
    "predicted_max_temperature = df_forecast['predicted_max_temperature'].max()\n",
    "#predicted_air_humidity = df_forecast['predicted_air_humidity'].mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "773c3351-b5c1-436b-ae28-263e63bd7327",
   "metadata": {},
   "source": [
    "indicators = {'current_avg_tensiometer': [X_target['avg_tens_lag1'].iloc[0]], 'predicted_avg_tensiometer': [predicted_avg_tensiometer],\n",
    "        'predicted_rain_amount': [predicted_rain_amount], 'predicted_max_temperature': [predicted_max_temperature]}\n",
    "indicators = pd.DataFrame(indicators)\n",
    "\n",
    "indicators"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f175c81-e9b7-481e-a070-e2be8248b04b",
   "metadata": {},
   "source": [
    "decision = model(\n",
    "    variables=fuzzy_variables,\n",
    "    rules=fuzzy_rules,\n",
    "    current_avg_tensiometer=indicators.at[0, 'current_avg_tensiometer'],\n",
    "    predicted_avg_tensiometer=indicators.at[0, 'predicted_avg_tensiometer'],\n",
    "    predicted_rain_amount=indicators.at[0, 'predicted_rain_amount'],\n",
    "    predicted_max_temperature=indicators.at[0, 'predicted_max_temperature'],\n",
    ")\n",
    "\n",
    "decision_defuzzy = round(decision[0]['decision'], 3)\n",
    "decision_fuzzy = fuzzy_decision(decision_defuzzy)\n",
    "\n",
    "print('Numerical Value:', decision_defuzzy)\n",
    "print('Fuzzy Value:', decision_fuzzy) "
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
